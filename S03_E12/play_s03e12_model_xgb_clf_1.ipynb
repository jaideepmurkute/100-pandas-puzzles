{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaideepmurkute/100-pandas-puzzles/blob/master/S03_E12/play_s03e12_model_xgb_clf_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ec7wkQrQzTZE",
        "outputId": "4e962781-1108-4100-da02-5e8766a9a0db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzjUcHUpQ7C5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "558b1dee-6074-43e4-e0b4-07a90373deda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "! pip install wandb -U -qqq\n",
        "! pip install sklearn -U -qqq\n",
        "! pip install xgboost -U -qqq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FUednWRAZ6l1",
        "outputId": "88fc41ee-b703-460c-b4e2-2b99b0703f62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.7.4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import xgboost\n",
        "xgboost.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nZvi96Dzcpj"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "import shutil\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "sns.set_style('darkgrid')\n",
        "from sklearn.datasets import fetch_california_housing \n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor, IsolationForest\n",
        "from sklearn.linear_model import LinearRegression, SGDOneClassSVM\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
        "# from sklearn.neighbors import LocalOutlierFactor\n",
        "# from sklearn.metrics import rmse\n",
        "\n",
        "from sklearn.model_selection import KFold, GroupKFold, StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, log_loss, mean_squared_error, cohen_kappa_score\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import xgboost as xgb\n",
        "import torch\n",
        "\n",
        "from scipy.stats.mstats import winsorize\n",
        "from scipy.stats import mode\n",
        "\n",
        "import wandb\n",
        "\n",
        "# import category_encoders as ce\n",
        "from sklearn.preprocessing import OrdinalEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpZBnKwWzcm7"
      },
      "outputs": [],
      "source": [
        "\n",
        "def set_seeds(config):\n",
        "  np.random.seed(config[\"random_state\"])\n",
        "  random.seed(config[\"random_state\"])\n",
        "  os.environ[\"PYTHONHASHSEED\"] = str(config[\"random_state\"])\n",
        "  '''\n",
        "  torch.manual_seed(config[\"random_state\"])\n",
        "  if torch.cuda.is_available():\n",
        "      torch.cuda.manual_seed(config[\"random_state\"])\n",
        "      torch.cuda.manual_seed_all(config[\"random_state\"])\n",
        "      torch.backends.cudnn.deterministic = True\n",
        "      torch.backends.cudnn.benchmark = True \n",
        "  '''\n",
        "\n",
        "\n",
        "def generate_fold_idx(config, train_df, group_col=None):\n",
        "  if config['fold_split_type'] == 'kfold':\n",
        "    splitter = KFold(n_splits=config['num_folds'], shuffle=True, \n",
        "                                     random_state=config['random_state'])\n",
        "  elif config['fold_split_type'] == 'strat_kfold':\n",
        "    splitter = StratifiedKFold(n_splits=config['num_folds'], shuffle=True, \n",
        "                                     random_state=config['random_state'])\n",
        "  elif config['fold_split_type'] == 'group_kfold':\n",
        "    splitter = GroupKFold(n_splits=config['num_folds'])\n",
        "  else:\n",
        "    raise ValueError(\"fold_split_type {} not recognized... Choose from: \\\n",
        "                    time_series_split, group_time_series_split, purged_time_series_split, kfold\")\n",
        "  \n",
        "  fold_idx_dict = dict()\n",
        "  if config['fold_split_type'] == 'group_kfold':\n",
        "    if group_col in train_df.columns:\n",
        "      for fold_idx, (train_idx, val_idx) in enumerate(splitter.split(X=train_df, \n",
        "                                                                    groups=train_df[group_col].values)):\n",
        "        fold_idx_dict[fold_idx] = dict()\n",
        "        fold_idx_dict[fold_idx]['train_idx'] = train_idx\n",
        "        fold_idx_dict[fold_idx]['val_idx'] = val_idx\n",
        "  else:\n",
        "    # if config['restrict_val_set_to_comp_data']:\n",
        "    #   comp_data_df = train_df[train_df.original_data==False]\n",
        "    #   for fold_idx, (train_idx, val_idx) in enumerate(splitter.split(X=comp_data_df, y=comp_data_df.quality.values)):\n",
        "    #     fold_idx_dict[fold_idx] = dict()\n",
        "    #     fold_idx_dict[fold_idx]['train_idx'] = train_idx\n",
        "    #     fold_idx_dict[fold_idx]['val_idx'] = val_idx\n",
        "    # else:\n",
        "    for fold_idx, (train_idx, val_idx) in enumerate(splitter.split(X=train_df, y=train_df.Class.values)):\n",
        "      fold_idx_dict[fold_idx] = dict()\n",
        "      fold_idx_dict[fold_idx]['train_idx'] = train_idx\n",
        "      fold_idx_dict[fold_idx]['val_idx'] = val_idx\n",
        "\n",
        "  return fold_idx_dict\n",
        "\n",
        "\n",
        "def save_model(config, model):\n",
        "  model_save_fname = config['model_name'] + '_fold_' + str(config['curr_fold']) + '.xgb'\n",
        "  \n",
        "  model_local_save_path = config['local_model_dir'] + '/' + model_save_fname\n",
        "  model_drive_save_path = config['drive_model_dir'] + '/' + model_save_fname\n",
        "\n",
        "  print('Saving model...', model_save_fname)\n",
        "  model.save_model(model_local_save_path)\n",
        "\n",
        "  print('Copying model to drive...')\n",
        "  shutil.copy(model_local_save_path, model_drive_save_path)\n",
        "  \n",
        "\n",
        "def load_model(config):\n",
        "  model_save_fname = config['model_name'] + '_fold_' + str(config['curr_fold']) + '.xgb'\n",
        "  \n",
        "  model_local_save_path = config['local_model_dir'] + '/' + model_save_fname\n",
        "  model_drive_save_path = config['drive_model_dir'] + '/' + model_save_fname\n",
        "\n",
        "  if not os.path.exists(model_local_save_path):\n",
        "    shutil.copy(model_drive_save_path, model_local_save_path)\n",
        "  \n",
        "  print('Loading model...', model_save_fname)\n",
        "  model = xgb.XGBClassifier()\n",
        "  # model = xgb.XGBRFClassifier()\n",
        "  model.load_model(model_local_save_path)\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "def get_xgb_params(config):\n",
        "  xgb_params = {\n",
        "            'random_state': config['random_state'], \n",
        "            'n_jobs': config['n_jobs'], \n",
        "            'verbosity': config['verbosity'], \n",
        "            \n",
        "            'booster': config['booster'], \n",
        "            'tree_method': config['tree_method'],  \n",
        "            'max_depth': config['max_depth'], \n",
        "            'max_leaves': config['max_leaves'], \n",
        "            'n_estimators': config['n_estimators'], \n",
        "            'early_stopping_rounds': config['early_stopping_rounds'], \n",
        "            \n",
        "            'colsample_bytree': config['colsample_bytree'], \n",
        "            'subsample': config['subsample'], \n",
        "            'reg_alpha': config['reg_alpha'], \n",
        "            'reg_lambda': config['reg_lambda'], \n",
        "            'enable_categorical': config['enable_categorical'], \n",
        "            'max_bin': config['max_bin'], \n",
        "            'min_child_weight': config['min_child_weight'], \n",
        "            \n",
        "            'learning_rate': config['learning_rate'], \n",
        "            'objective': config['objective'], \n",
        "            \n",
        "            'eval_metric': config['eval_metric'],\n",
        "            # 'eval_metric': cohen,\n",
        "\n",
        "            'sample_type': config['sample_type'],  \n",
        "            'normalize_type': config['normalize_type'],  \n",
        "            'rate_drop': config['rate_drop'], \n",
        "            'skip_drop': config['skip_drop'], \n",
        "        }\n",
        "  \n",
        "  return xgb_params\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVyxTmmV1mTT"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_data(config):\n",
        "  for fname in ['train.csv', 'test.csv', 'sample_submission.csv']:\n",
        "    shutil.copy(os.path.join(config['drive_data_dir'], fname), \n",
        "                os.path.join(config['local_data_dir'], fname)\n",
        "                )\n",
        "  train_df = pd.read_csv(os.path.join(config['local_data_dir'], 'train.csv'))\n",
        "  test_df = pd.read_csv(os.path.join(config['local_data_dir'], 'test.csv'))\n",
        "  sub_df = pd.read_csv(os.path.join(config['local_data_dir'], 'sample_submission.csv'))\n",
        "  print(\"Read shape: train_df.shape: \", train_df.shape)\n",
        "  print(\"Read shape: test_df.shape: \", test_df.shape)\n",
        "  print(\"Read shape: sub_df.shape: \", sub_df.shape)\n",
        "  \n",
        "  # train_df.drop(['id'], axis=1, inplace=True)\n",
        "  train_df['original_data'] = False\n",
        "    \n",
        "  # fetch orig_data\n",
        "  for fname in ['orig_data.csv']:\n",
        "    shutil.copy(os.path.join(config['drive_data_dir'], fname), \n",
        "                os.path.join(config['local_data_dir'], fname)\n",
        "                )\n",
        "  orig_data_df = pd.read_csv(os.path.join(config['local_data_dir'], 'orig_data.csv'))\n",
        "  \n",
        "  # print('-'*30)\n",
        "  # print(\"Before duplicate removal: \")\n",
        "  # print('orig_data_df.shape: ', orig_data_df.shape)\n",
        "  # orig_data_df.drop_duplicates(inplace=True)\n",
        "  # print(\"After duplicate removal: \")\n",
        "  # print('orig_data_df.shape: ', orig_data_df.shape)\n",
        "  # print('-'*30)\n",
        "\n",
        "  orig_data_df['original_data'] = True\n",
        "  orig_data_df['id'] = np.arange(orig_data_df.shape[0])\n",
        "  \n",
        "  return train_df, test_df, sub_df, orig_data_df\n",
        "  \n",
        "\n",
        "def encode_data(config, train_df, test_df):\n",
        "\n",
        "  # Encode labels to be from 0 to n_categories-1  \n",
        "  oe = OrdinalEncoder()\n",
        "  train_labels = np.reshape(train_df.quality.values, newshape=(train_df.shape[0], 1))\n",
        "  train_df['quality'] = oe.fit_transform(train_labels)\n",
        "  \n",
        "  return train_df, test_df, oe\n",
        "\n",
        "\n",
        "def get_feature_cols(config, train_df):\n",
        "  config['id_cols'] = ['id', 'original_data']\n",
        "\n",
        "  config['target_cols'] = ['Class']\n",
        "  \n",
        "  config['non_feature_cols'] = config['id_cols'] + config['target_cols']\n",
        "\n",
        "  config['feature_cols'] = []\n",
        "  for col in train_df.columns:\n",
        "    if col not in config['non_feature_cols']:\n",
        "      config['feature_cols'].append(col)\n",
        "  \n",
        "  return config\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PDWoJqBpN6x"
      },
      "outputs": [],
      "source": [
        "\n",
        "def scale_data_fn(config, train_df, test_df):\n",
        "  \n",
        "  cols_to_scale = config['feature_cols'] # MAKE SURE THESE ARE ALL CONT. FEATURES.\n",
        "\n",
        "  if config['scaler_type'] == 'standard':\n",
        "    scaler = StandardScaler()\n",
        "  elif config['scaler_type'] == 'robust':\n",
        "    scaler = RobustScaler()\n",
        "  elif config['scaler_type'] == 'minmax':\n",
        "    scaler = MinMaxScaler()\n",
        "  \n",
        "  scaler.fit(train_df[cols_to_scale])\n",
        "  train_df[cols_to_scale] = scaler.transform(train_df[cols_to_scale])\n",
        "  test_df[cols_to_scale] = scaler.transform(test_df[cols_to_scale])\n",
        "\n",
        "  return train_df, test_df\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ul39e-gKyZga"
      },
      "outputs": [],
      "source": [
        "\n",
        "def IQR_outlier_handling(train_df, test_df, cols, handling_type):\n",
        "  for col in cols:\n",
        "    # calculate interquartile range\n",
        "    q25, q75 = np.percentile(train_df[col].values, 25), np.percentile(train_df[col].values, 75)\n",
        "    iqr = q75 - q25\n",
        "    \n",
        "    # calculate the outlier cutoff\n",
        "    cut_off = iqr * 1.5\n",
        "    lower_cutoff, upper_cutoff = q25 - cut_off, q75 + cut_off\n",
        "    \n",
        "    num_outliers = train_df[col].loc[(train_df[col] < lower_cutoff) | (train_df[col] > upper_cutoff)].shape[0]\n",
        "    print(\"col: {} \\t # num_outliers: {}\".format(col, num_outliers))\n",
        "\n",
        "    if handling_type == 'remove_train_clip_test':\n",
        "      train_df[col] = train_df[col].loc[(not(train_df[col] < lower_cutoff)) & (not(train_df[col] > upper_cutoff))]\n",
        "      if col in test_df.columns:\n",
        "        test_df[col].loc[test_df[col] < lower_cutoff] = lower_cutoff\n",
        "        test_df[col].loc[test_df[col] > upper_cutoff] = upper_cutoff\n",
        "    elif handling_type == 'clip':\n",
        "      train_df[col].loc[train_df[col] < lower_cutoff] = lower_cutoff\n",
        "      train_df[col].loc[train_df[col] > upper_cutoff] = upper_cutoff\n",
        "      if col in test_df.columns:\n",
        "        test_df[col].loc[test_df[col] < lower_cutoff] = lower_cutoff\n",
        "        test_df[col].loc[test_df[col] > upper_cutoff] = upper_cutoff\n",
        "      \n",
        "    return train_df, test_df\n",
        "\n",
        "\n",
        "\n",
        "def winsorize_outlier_handling(train_df, test_df, cols, lower_lim=0.01, upper_lim=0.98):\n",
        "  # lower_lim = train_df.quantile(0.01)\n",
        "  # upper_lim = train_df.quantile(0.99)\n",
        "  for col in cols:\n",
        "    train_df[col] = winsorize(train_df[col], (lower_lim, upper_lim))\n",
        "    test_df[col] = winsorize(test_df[col], (lower_lim, upper_lim))\n",
        "  \n",
        "  return train_df, test_df\n",
        "\n",
        "\n",
        "\n",
        "def isolation_forest_outlier_handling(train_df, test_df, cols, outlier_thresh=-0.1, \n",
        "                                      handling_method='drop_median', seed=0):\n",
        "  print(\"Training Isolation forest model to detect outliers...\")\n",
        "  iso_forest_model = IsolationForest(n_estimators=500, contamination='auto', random_state=seed)\n",
        "  iso_forest_model.fit(train_df[cols], train_df.MedHouseVal.values)\n",
        "  \n",
        "  sample_scores_train = iso_forest_model.decision_function(train_df[cols])\n",
        "  sample_scores_test = iso_forest_model.decision_function(test_df[cols])\n",
        "\n",
        "  print(\"# train outliers: \", np.sum(sample_scores_train < outlier_thresh))\n",
        "  print(\"# test outliers: \", np.sum(sample_scores_test < outlier_thresh))\n",
        "  \n",
        "  if handling_method == 'drop_median':\n",
        "    print(\"Dropping outlier train samples...\")\n",
        "    # drop train samples and replace test sample values with median from train columns\n",
        "    train_df = train_df.loc[sample_scores_train >= outlier_thresh]\n",
        "    \n",
        "    print(\"Clipping outlier test samples to median value...\")\n",
        "    for col in cols:\n",
        "      test_df[col].loc[sample_scores_test < outlier_thresh] = train_df[col].median(axis=0)\n",
        "  elif handling_method == 'winsorize':\n",
        "    train_df.loc[sample_scores_train < outlier_thresh] = winsorize_outlier_handling(train_df.loc[sample_scores_train < outlier_thresh], \n",
        "                                                                  cols, lower_lim=0.01, upper_lim=0.98)\n",
        "    test_df.loc[sample_scores_test < outlier_thresh] = winsorize_outlier_handling(test_df.loc[sample_scores_test < outlier_thresh], \n",
        "                                                                  cols, lower_lim=0.01, upper_lim=0.98)\n",
        "    \n",
        "  return train_df, test_df\n",
        "\n",
        "\n",
        "def handle_outliers(config, train_df, test_df):\n",
        "  cols = config['feature_cols']\n",
        "\n",
        "  if config['outlier_handling_method'] == 'winsorize':\n",
        "    train_df, test_df = winsorize_outlier_handling(train_df, test_df, cols=cols)\n",
        "  elif config['outlier_handling_method'] == 'iso_forest':\n",
        "    train_df, test_df = isolation_forest_outlier_handling(train_df, test_df, cols=cols, \n",
        "                                  outlier_thresh=-0.1, handling_method='drop_median', seed=config['seed'])\n",
        "  elif config['outlier_handling_method'] == 'iqr':\n",
        "    train_df, test_df = IQR_outlier_handling(train_df, test_df, cols, handling_type='clip')\n",
        "\n",
        "  return train_df, test_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLHcvaiBLFJs"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def get_config():\n",
        "  return config\n",
        "\n",
        "\n",
        "def save_config(config):\n",
        "  config_to_save = {}  # to avoid types like object or others that somtimes cause problem reading data back.\n",
        "  for k, v in config.items():\n",
        "    if isinstance(v, (bool, int, float, str, list, dict, type(None))):\n",
        "      config_to_save[k] = v\n",
        "  \n",
        "  config_local_save_path = os.path.join(config['local_model_dir'], 'saved_config.json')\n",
        "  config_drive_save_path = os.path.join(config['drive_model_dir'], 'saved_config.json')\n",
        "  \n",
        "  with open(config_local_save_path, 'w') as fp:\n",
        "    json.dump(config_to_save, fp, indent=4, sort_keys=True)\n",
        "  \n",
        "  shutil.copy(config_local_save_path, config_drive_save_path)\n",
        "\n",
        "\n",
        "def save_fold_idx(config, fold_idx_dict):\n",
        "  fold_idx_local_save_path = os.path.join(config['local_model_dir'], 'fold_idx_dict.pkl')\n",
        "  fold_idx_drive_save_path = os.path.join(config['drive_model_dir'], 'fold_idx_dict.pkl')\n",
        "  \n",
        "  with open(fold_idx_local_save_path, 'wb') as fp:\n",
        "    pickle.dump(fold_idx_dict, fp)\n",
        "  \n",
        "  shutil.copy(fold_idx_local_save_path, fold_idx_drive_save_path)\n",
        "\n",
        "\n",
        "def load_fold_idx(config):\n",
        "  fold_idx_local_save_path = os.path.join(config['local_model_dir'], 'fold_idx_dict.pkl')\n",
        "  fold_idx_drive_save_path = os.path.join(config['drive_model_dir'], 'fold_idx_dict.pkl')\n",
        "  \n",
        "  shutil.copy(fold_idx_drive_save_path, fold_idx_local_save_path)\n",
        "\n",
        "  with open(fold_idx_local_save_path, 'rb') as fp:\n",
        "    fold_idx_dict = pickle.load(fp)\n",
        "  \n",
        "  return fold_idx_dict\n",
        "\n",
        "\n",
        "def get_model_config(config):\n",
        "  config_local_save_path = os.path.join(config['local_model_dir'], 'saved_config.json')\n",
        "  config_drive_save_path = os.path.join(config['drive_model_dir'], 'saved_config.json')\n",
        "  \n",
        "  shutil.copy(config_drive_save_path, config_local_save_path)\n",
        "\n",
        "  with open(config_local_save_path, 'r') as fp:\n",
        "    model_config = json.load(fp)\n",
        "  \n",
        "  return model_config\n",
        "\n",
        "'''\n",
        "'id', 'Mean_Integrated', 'SD', 'EK', 'Skewness', 'Mean_DMSNR_Curve',\n",
        "'SD_DMSNR_Curve', 'EK_DMSNR_Curve', 'Skewness_DMSNR_Curve', 'Class'\n",
        "'''\n",
        "def across_col_feat_v1(config, df):\n",
        "  feat_cols = []\n",
        "  for col in df.columns:\n",
        "    if col not in ['id', 'Class', 'original_data']:\n",
        "      feat_cols.append(col)\n",
        "  \n",
        "  for col1 in feat_cols:\n",
        "    for col2 in feat_cols:\n",
        "      if col1 == col2: \n",
        "        continue\n",
        "      temp_df = pd.DataFrame([])\n",
        "      temp_df[col1 + '_by_' + col2] = df[col1] / (df[col2]+1e-4)\n",
        "      df = pd.concat((df, temp_df), axis=1)\n",
        "      \n",
        "  for col1 in feat_cols:\n",
        "    for col2 in feat_cols:\n",
        "      if col1 == col2: \n",
        "        continue\n",
        "      temp_df = pd.DataFrame([])\n",
        "      temp_df[col1 + '_into_' + col2] = df[col1] * df[col2]\n",
        "      df = pd.concat((df, temp_df), axis=1)\n",
        "  \n",
        "  for col in feat_cols:\n",
        "    temp_df = pd.DataFrame([])\n",
        "    temp_df[col + '_square'] = df[col]**2\n",
        "    df = pd.concat((df, temp_df), axis=1)\n",
        "  \n",
        "  for col in feat_cols:\n",
        "    if df[col].min() > 0:\n",
        "      temp_df = pd.DataFrame([])\n",
        "      temp_df[col + '_sqrt'] = df[col]**0.5\n",
        "      df = pd.concat((df, temp_df), axis=1)\n",
        "  \n",
        "  for col in feat_cols:\n",
        "    temp_df = pd.DataFrame([])\n",
        "    temp_df[col + '_cube'] = df[col]**3\n",
        "    df = pd.concat((df, temp_df), axis=1)\n",
        "  \n",
        "  for col in feat_cols:\n",
        "    if df[col].min() > 0:\n",
        "      temp_df = pd.DataFrame([])\n",
        "      temp_df[col+'_log'] = np.log(df[col]+1e-4)\n",
        "      df = pd.concat((df, temp_df), axis=1)\n",
        "  \n",
        "  for col in feat_cols:\n",
        "    temp_df = pd.DataFrame([])\n",
        "    temp_df[col + '_exp'] = np.exp(df[col])\n",
        "    df = pd.concat((df, temp_df), axis=1)\n",
        "  \n",
        "  # ------------------------\n",
        "\n",
        "  for col in df.columns:\n",
        "    nan_cnt = np.sum(np.isnan(df[col]))\n",
        "    inf_cnt = np.sum(np.isinf(df[col]))\n",
        "    raise_exp = False\n",
        "    if nan_cnt > 0:\n",
        "      raise_exp = True\n",
        "      print(f\"column {col} has {nan_cnt} nans...\")\n",
        "    if inf_cnt > 0:\n",
        "      raise_exp = True\n",
        "      print(f\"column {col} has {inf_cnt} infs...\")\n",
        "    \n",
        "    if raise_exp: \n",
        "      print(f\"Dropping column: {col}\")\n",
        "      df.drop(col, axis=1, inplace=True)\n",
        "      print(\"-\"*30)\n",
        "  \n",
        "  # if raise_exp: raise\n",
        "\n",
        "  return df\n",
        "\n",
        "'''\n",
        "'id', 'Mean_Integrated', 'SD', 'EK', 'Skewness', 'Mean_DMSNR_Curve',\n",
        "'SD_DMSNR_Curve', 'EK_DMSNR_Curve', 'Skewness_DMSNR_Curve', 'Class'\n",
        "\n",
        "Skewness-kurtosis diagram: This is a graphical representation of the skewness and kurtosis of a distribution, \n",
        "and it can be used to compare the shapes of different distributions. \n",
        "Pulsars are expected to have high kurtosis and low skewness values, and you can plot the skewness \n",
        "and kurtosis of the radio wave recording on the diagram to determine if it is consistent with a pulsar signal.\n",
        "\n",
        "'''\n",
        "def across_col_feat_v2(config, df):\n",
        "  feat_cols = []\n",
        "  for col in df.columns:\n",
        "    if col not in ['id', 'Class', 'original_data']:\n",
        "      feat_cols.append(col)\n",
        "  \n",
        "  # -------\n",
        "  # observations confidence intervals\n",
        "  for ci_mult in [1,2,3]:\n",
        "    temp_df = pd.DataFrame([])\n",
        "    temp_df['CI_'+str(ci_mult)+'_pos_observations'] = df['Mean_Integrated'] + (ci_mult*df['SD'])\n",
        "    temp_df['CI_'+str(ci_mult)+'_neg_observations'] = df['Mean_Integrated'] - (ci_mult*df['SD'])\n",
        "    \n",
        "    df = pd.concat([df, temp_df], axis=1)\n",
        "\n",
        "  # Dispersion Measure (DM) SNR(Signal-to-Noise ratio) confidence intervals\n",
        "  for ci_mult in [1,2,3]:\n",
        "    temp_df = pd.DataFrame([])\n",
        "    temp_df['CI_'+str(ci_mult)+'_pos_DMSNR'] = df['Mean_DMSNR_Curve'] + (ci_mult*df['SD_DMSNR_Curve'])\n",
        "    temp_df['CI_'+str(ci_mult)+'_neg_DMSNR'] = df['Mean_DMSNR_Curve'] - (ci_mult*df['SD_DMSNR_Curve'])\n",
        "    \n",
        "    df = pd.concat([df, temp_df], axis=1)\n",
        "  \n",
        "  # -------\n",
        "  # observations variance\n",
        "  df['var_observations'] = df['SD']**2\n",
        "\n",
        "  # DMSNR variance\n",
        "  df['var_DMSNR'] = df['SD_DMSNR_Curve']**2\n",
        "\n",
        "  # -------\n",
        "  # coef of variation - observations\n",
        "  df['coef_variation_observations'] = df['var_observations'] / df['Mean_Integrated']\n",
        "  \n",
        "  # coef of variation - DMSNR\n",
        "  df['coef_variation_DMSNR'] = df['var_DMSNR'] / df['Mean_DMSNR_Curve']\n",
        "  \n",
        "  # -------\n",
        "  # modulation index - observations\n",
        "  df['mod_index_observations'] = df['SD'] / df['Mean_Integrated']\n",
        "  \n",
        "  # modulation index - DMSNR\n",
        "  df['mod_index_DMSNR'] = df['SD_DMSNR_Curve'] / df['Mean_DMSNR_Curve']\n",
        "\n",
        "  # -------\n",
        "  # Pulsars are expected to have high kurtosis and low skewness values\n",
        "  df['skew_by_excess_kurt_observations'] = df['Skewness'] / df['EK']\n",
        "  df['excess_kurt_by_skewness_observations'] = df['EK'] / df['Skewness']\n",
        "  df['skew_by_excess_kurt_DMSNR'] = df['Skewness_DMSNR_Curve'] / df['EK_DMSNR_Curve']\n",
        "  df['excess_kurt_by_skewness_DMSNR'] = df['EK_DMSNR_Curve'] / df['Skewness_DMSNR_Curve']\n",
        "  df['skew_into_kurt_observations'] = df['Skewness'] * df['EK']\n",
        "  df['skew_into_kurt_DMSNR'] = df['Skewness_DMSNR_Curve'] * df['EK_DMSNR_Curve']\n",
        "  \n",
        "  return df\n",
        "\n",
        "\n",
        "\n",
        "def extract_features(config, train_df, test_df):\n",
        "  if config['feature_version'] is None:\n",
        "    pass\n",
        "  elif config['feature_version'] == 'v1':\n",
        "    train_df = across_col_feat_v1(config, train_df)\n",
        "    test_df = across_col_feat_v1(config, test_df)\n",
        "  elif config['feature_version'] == 'v2':\n",
        "    train_df = across_col_feat_v2(config, train_df)\n",
        "    test_df = across_col_feat_v2(config, test_df)\n",
        "  else:\n",
        "    print(\"Feature version {} not supported. Choose from : None, v1\")\n",
        "  \n",
        "  return train_df, test_df\n",
        "    \n",
        "\n",
        "# consider prior distribution of labels?\n",
        "def find_optimal_cuts():\n",
        "  pass\n",
        "\n",
        "\n",
        "def convert_cont_preds_to_int(preds):\n",
        "  # can do this in many ways - \n",
        "  # use round()\n",
        "  # find optimal splits\n",
        "  # find optimal splits considering label priors etc.\n",
        "\n",
        "  preds = np.round(preds)\n",
        "\n",
        "  return preds\n",
        "\n",
        "\n",
        "# # def wqkappa(predt: np.ndarray, dtrain: xgb.DMatrix) -> Tuple[str, float]:\n",
        "# def wqkappa(predt: np.ndarray, dtrain: xgb.DMatrix):\n",
        "#   ''' Weighted quadratic metric.'''\n",
        "  \n",
        "#   y = dtrain.get_label()\n",
        "  \n",
        "#   # predt[predt < -1] = -1 + 1e-6\n",
        "#   # elements = np.power(np.log1p(y) - np.log1p(predt), 2)\n",
        "#   wqkappa_score = cohen_kappa_score(y, predt, weights='quadratic')\n",
        "#   return 'wqkappa', wqkappa_score\n",
        "\n",
        "\n",
        "\n",
        "# def wqkappa(pred: np.ndarray, label: np.ndarray):\n",
        "#   ''' Weighted quadratic metric.'''\n",
        "#   wqkappa_score = cohen_kappa_score(label, pred, weights='quadratic')\n",
        "\n",
        "#   return 'wqkappa', wqkappa_score\n",
        "\n",
        "\n",
        "def wqkappa(label, pred):\n",
        "  ''' Weighted quadratic metric.'''\n",
        "\n",
        "  # pred_int = convert_cont_preds_to_int(pred)\n",
        "  pred_cls = np.argmax(pred, axis=1)\n",
        "  \n",
        "  wqkappa_score = cohen_kappa_score(label, pred_cls, weights='quadratic')\n",
        "  # print(\"wqkappa_score: \", wqkappa_score)\n",
        "  # raise\n",
        "\n",
        "  # return 'wqkappa', wqkappa_score\n",
        "  return -1*wqkappa_score\n",
        "\n",
        "\n",
        "def pca_dim_red(config, train_df, test_df): \n",
        "    pca_obj = PCA(n_components=0.99, svd_solver='full', whiten=False, copy=True, tol=0.0)\n",
        "\n",
        "    print(\"Before PCA transform:::::::\")\n",
        "    print(\"train_df.shape: \", train_df.shape)\n",
        "    print(\"test_df.shape: \", train_df.shape)\n",
        "    train_df_trans = pca_obj.fit_transform(train_df[config['feature_cols']])\n",
        "    test_df_trans = pca_obj.transform(test_df[config['feature_cols']])\n",
        "    print(\"After PCA transform:::::::\")\n",
        "    print(\"train_df_trans.shape: \", train_df_trans.shape)\n",
        "    print(\"test_df_trans.shape: \", test_df_trans.shape)\n",
        "\n",
        "    non_feat_train_cols = [col for col in train_df.columns if col not in config['feature_cols']]\n",
        "    non_feat_test_cols = [col for col in test_df.columns if col not in config['feature_cols']]\n",
        "    \n",
        "    pca_df_col_names = []\n",
        "    for i in range(train_df_trans.shape[1]):\n",
        "      pca_df_col_names.append('pca_'+str(i))\n",
        "\n",
        "    train_df_trans = pd.DataFrame(train_df_trans, columns=pca_df_col_names)\n",
        "    test_df_trans = pd.DataFrame(test_df_trans, columns=pca_df_col_names)\n",
        "\n",
        "    \n",
        "    train_df = pd.concat((train_df_trans.reset_index(drop=True), \n",
        "                          train_df[non_feat_train_cols].reset_index(drop=True)), axis=1)\n",
        "    test_df = pd.concat((test_df_trans.reset_index(drop=True), \n",
        "                         test_df[non_feat_test_cols].reset_index(drop=True)), axis=1)\n",
        "\n",
        "    print(\">>>>\")\n",
        "    print(\"After merging PCA feats with non feature cols::::\")\n",
        "    print(\"train_df.shape: \", train_df.shape)\n",
        "    print(\"test_df.shape: \", test_df.shape)\n",
        "    \n",
        "    return train_df, test_df\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEEIFAjRzckV"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_k_folds():\n",
        "\n",
        "  # needed becuse variable that is updated within function becomes a local variable and has to be passed in.\n",
        "  config = get_config()\n",
        "  \n",
        "  create_paths(config)\n",
        "  train_df, test_df, sub_df, orig_data_df = get_data(config)\n",
        "  print(\"train_df.shape: \", train_df.shape)\n",
        "  print(\"test_df.shape: \", test_df.shape)\n",
        "  print(\"sub_df.shape: \", sub_df.shape)\n",
        "  print(\"orig_data_df.shape: \", orig_data_df.shape)\n",
        "  \n",
        "  # ------------------------------------------\n",
        "  \n",
        "  if config['validate_only_comp_data']:\n",
        "    fold_idx_dict = generate_fold_idx(config, train_df)\n",
        "\n",
        "  if config['include_orig_data']: \n",
        "    train_df = pd.concat((train_df, orig_data_df), axis=0)\n",
        "    print(\"After appending orig data to train data: \")\n",
        "    print(\"train_df.shape: \", train_df.shape)\n",
        "  \n",
        "  if not config['validate_only_comp_data']:\n",
        "    fold_idx_dict = generate_fold_idx(config, train_df)\n",
        "  \n",
        "  for fold_num in fold_idx_dict.keys():\n",
        "    val_idx = fold_idx_dict[fold_num]['val_idx']\n",
        "    all_idx = np.arange(0, train_df.shape[0])\n",
        "    train_idx = np.setdiff1d(all_idx, val_idx)\n",
        "    fold_idx_dict[fold_num]['train_idx'] = train_idx\n",
        "  \n",
        "  # ------------------------------------------\n",
        "\n",
        "  for fold_num in fold_idx_dict.keys():\n",
        "    val_idx = fold_idx_dict[fold_num]['val_idx']\n",
        "    all_idx = np.arange(0, train_df.shape[0])\n",
        "    train_idx = np.setdiff1d(all_idx, val_idx)\n",
        "    fold_idx_dict[fold_num]['train_idx'] = train_idx\n",
        "  \n",
        "  print(\"Saving fold_idx_dict...\")\n",
        "  save_fold_idx(config, fold_idx_dict)\n",
        "\n",
        "  # ---------------\n",
        "  \n",
        "  # train_df, test_df, label_encoder = encode_data(config, train_df, test_df)\n",
        "  # print(\"After feature encoding: train_df.shape: \", train_df.shape)\n",
        "  # print(\"After feature encoding: test_df.shape: \", test_df.shape)\n",
        "  \n",
        "  # ---------------\n",
        "\n",
        "  print(\"Before feature extraction: train_df.shape: \", train_df.shape)\n",
        "  print(\"Before feature extraction: test_df.shape: \", test_df.shape)\n",
        "  train_df, test_df = extract_features(config, train_df, test_df)\n",
        "  print(\"After feature extraction: train_df.shape: \", train_df.shape)\n",
        "  print(\"After feature extraction: test_df.shape: \", test_df.shape)\n",
        "  \n",
        "  # ---------------\n",
        "\n",
        "  config = get_feature_cols(config, train_df)\n",
        "  print(\"config['feature_cols']): \", config['feature_cols'])\n",
        "  print(\"# feature_cols: \", len(config['feature_cols']))\n",
        "\n",
        "  # ---------------\n",
        "  \n",
        "  if config['handle_outliers']:\n",
        "    print(\"Before outlier handling: \")\n",
        "    print(f\"train_df.shape: {train_df.shape} \\t test_df.shape: {test_df.shape}\")\n",
        "    train_df, test_df = handle_outliers(config, train_df, test_df)\n",
        "    print(\"After outlier handling: \")\n",
        "    print(f\"train_df.shape: {train_df.shape} \\t test_df.shape: {test_df.shape}\")\n",
        "  \n",
        "  # ---------------\n",
        "  if config['dim_reduction'] and config['dim_red_method']=='PCA':\n",
        "    config['scale_data'] = True\n",
        "  \n",
        "  if config['scale_data']:\n",
        "    train_df, test_df = scale_data_fn(config, train_df, test_df)\n",
        "  \n",
        "  # ------------------\n",
        "  \n",
        "  if config['dim_reduction']:\n",
        "    if config['dim_red_method']=='PCA':\n",
        "      train_df, test_df = pca_dim_red(config, train_df, test_df)\n",
        "    elif config['dim_red_method']=='UMAP':\n",
        "      print(\"dim reduction method UMAP not yet supported...\")\n",
        "    else: \n",
        "      raise\n",
        "    \n",
        "  config = get_feature_cols(config, train_df)\n",
        "  print(\"config['feature_cols']): \", config['feature_cols'])\n",
        "  print(\"# feature_cols: \", len(config['feature_cols']))\n",
        "\n",
        "\n",
        "  # ------------------------\n",
        "  \n",
        "  per_model_metrics = {\n",
        "                        'AUROC': {'train': [], 'val': []},\n",
        "                        'f1_score': {'train': [], 'val': []},\n",
        "                        'logloss': {'train': [], 'val': []},\n",
        "                      }\n",
        "  \n",
        "  shutil.copy('/content/drive/MyDrive/Playground Series/S03_E12/code/play_s03e12_model_xgb_clf_1.ipynb', \n",
        "              os.path.join(config['drive_model_dir'], 'play_s03e12_model_xgb_clf_1.ipynb'))\n",
        "  save_config(config)\n",
        "\n",
        "  # ------------\n",
        "\n",
        "  # fold_model_name = config['model_name'] + '_fold_' + str(config['curr_fold'])\n",
        "  # if config['use_wandb']:\n",
        "  wandb.init(name=config['model_name'], project=config['project_name'], \n",
        "            tags=['baseline'], config=config)\n",
        "  if config['choice'] == 3:\n",
        "    print(\"Updating sweep configs...\")\n",
        "    for k, v in wandb.config.items():\n",
        "      config[k] = v\n",
        "    print(\"*** Updated sweep config: \", config)\n",
        "  \n",
        "  # ------------\n",
        "\n",
        "  for fold_num in range(config['num_folds']):\n",
        "    if fold_num not in config['folds_to_train']:\n",
        "      continue\n",
        "\n",
        "    print(\"Training fold: \", fold_num)\n",
        "    config['curr_fold'] = fold_num\n",
        "\n",
        "    # -----------\n",
        "    # fold_model_name = config['model_name'] + '_fold_' + str(config['curr_fold'])\n",
        "    # # if config['use_wandb']:\n",
        "    # wandb.init(name=fold_model_name, project=config['project_name'], \n",
        "    #           tags=['baseline'], config=config)\n",
        "    # if config['choice'] == 3:\n",
        "    #   print(\"Updating sweep configs...\")\n",
        "    #   for k, v in wandb.config.items():\n",
        "    #     config[k] = v\n",
        "    #   print(\"*** Updated sweep config: \", config)\n",
        "    \n",
        "    set_seeds(config)\n",
        "    \n",
        "    # -----------\n",
        "    \n",
        "    train_idx = fold_idx_dict[fold_num]['train_idx']\n",
        "    val_idx = fold_idx_dict[fold_num]['val_idx']\n",
        "    print(\"len(train_idx): {} \\t len(val_idx): {}\".format(len(train_idx), len(val_idx)))\n",
        "    \n",
        "    train_data = train_df[config['feature_cols']].iloc[train_idx]\n",
        "    train_label = train_df[config['target_cols']].iloc[train_idx]\n",
        "\n",
        "    val_data = train_df[config['feature_cols']].iloc[val_idx]\n",
        "    val_label = train_df[config['target_cols']].iloc[val_idx]\n",
        "\n",
        "    xgb_params = get_xgb_params(config)\n",
        "\n",
        "    if config['scale_pos_weight'] == 'auto':\n",
        "      auto_pos_cls_weight = train_label[train_label.values==0].shape[0] / train_label[train_label.values==1].shape[0]\n",
        "      print(\"Setting scale_pos_weight to: \", auto_pos_cls_weight)\n",
        "      xgb_params['scale_pos_weight'] = auto_pos_cls_weight\n",
        "    else:\n",
        "      xgb_params['scale_pos_weight'] = config['scale_pos_weight']\n",
        "    \n",
        "    model = xgb.XGBClassifier(**xgb_params)\n",
        "    \n",
        "    print(\"Training model ...\")\n",
        "    model.fit(train_data, train_label, \n",
        "              eval_set=[(train_data, train_label), \n",
        "                        (val_data, val_label)], \n",
        "              verbose=50, \n",
        "              # early_stopping_rounds=config['early_stopping_rounds']\n",
        "              )\n",
        "    \n",
        "    print(\"Saving Model...\")\n",
        "    save_model(config, model)\n",
        "\n",
        "    # -----------\n",
        "    # print(model.evals_result())\n",
        "    if config['choice'] == 1:\n",
        "      for i in range(len(model.evals_result()['validation_0'][config['eval_metric']])):\n",
        "        wandb.log({\n",
        "          f\"Per Epoch Train {config['eval_metric']}\": model.evals_result()['validation_0'][config['eval_metric']][i], \n",
        "          f\"Per Epoch Val {config['eval_metric']}\": model.evals_result()['validation_1'][config['eval_metric']][i], \n",
        "          }\n",
        "        )\n",
        "    \n",
        "    if config['eval_metric'] in ['loss', 'wqkappa', 'logloss']:\n",
        "      # Using min and argmin here since eval metric is -1*kappa; \n",
        "      # since xgboost does not seem to have option to specify if custom eval_metric should maximize or minimize\n",
        "      # So results in improper early stopping.\n",
        "      print(\"Best val epoch: max validation_1 metric: \", \n",
        "            np.min(model.evals_result()['validation_1'][config['eval_metric']]))\n",
        "      print(\"Best val epoch number:  \", np.argmin(model.evals_result()['validation_1'][config['eval_metric']]))\n",
        "    else:\n",
        "      print(\"Best val epoch: max validation_1 metric: \", \n",
        "            np.max(model.evals_result()['validation_1'][config['eval_metric']]))\n",
        "      print(\"Best val epoch number:  \", np.argmax(model.evals_result()['validation_1'][config['eval_metric']]))\n",
        "    \n",
        "    print(\"model.best_ntree_limit: \", model.best_ntree_limit)\n",
        "\n",
        "    \n",
        "    # ------------------\n",
        "    \n",
        "    train_pred_probs = model.predict_proba(train_data, ntree_limit=model.best_ntree_limit)\n",
        "    val_pred_probs = model.predict_proba(val_data, ntree_limit=model.best_ntree_limit)\n",
        "    train_preds = np.argmax(train_pred_probs, axis=1)\n",
        "    val_preds = np.argmax(val_pred_probs, axis=1)\n",
        "    \n",
        "    # ------------------\n",
        "\n",
        "    train_auroc = roc_auc_score(train_label.values, train_pred_probs[:, 1])\n",
        "    val_auroc = roc_auc_score(val_label.values, val_pred_probs[:, 1])\n",
        "    \n",
        "    train_logloss = log_loss(train_label.values, train_pred_probs[:, 1])\n",
        "    val_logloss = log_loss(val_label.values, val_pred_probs[:, 1])\n",
        "    \n",
        "    train_f1 = f1_score(train_label.values, train_preds, average='weighted')\n",
        "    val_f1 = f1_score(val_label.values, val_preds, average='weighted')\n",
        "    \n",
        "    # ------------------\n",
        "\n",
        "    per_model_metrics['logloss']['train'].append(train_logloss)\n",
        "    per_model_metrics['logloss']['val'].append(val_logloss)\n",
        "    per_model_metrics['AUROC']['train'].append(train_auroc)\n",
        "    per_model_metrics['AUROC']['val'].append(val_auroc)\n",
        "    per_model_metrics['f1_score']['train'].append(train_f1)\n",
        "    per_model_metrics['f1_score']['val'].append(val_f1)\n",
        "    \n",
        "    print(f\"Logloss: Train: {train_logloss} \\t Val: {val_logloss}\")\n",
        "    print(f\"AUROC: Train: {train_auroc} \\t Val: {val_auroc}\")\n",
        "    print(f\"F1 score: Train: {train_f1} \\t Val: {val_f1}\")\n",
        "    \n",
        "    print('-'*30)\n",
        "  \n",
        "  print(\"Fold average stats.: \")\n",
        "  print(f\"Logloss: Train: {np.mean(per_model_metrics['logloss']['train'])} \\t Val: {np.mean(per_model_metrics['logloss']['val'])}\")\n",
        "  print(f\"AUROC: Train: {np.mean(per_model_metrics['AUROC']['train'])} \\t Val: {np.mean(per_model_metrics['AUROC']['val'])}\")\n",
        "  print(f\"F1 score: Train: {np.mean(per_model_metrics['f1_score']['train'])} \\t Val: {np.mean(per_model_metrics['f1_score']['val'])}\")\n",
        "  \n",
        "  print(\"Per fold train logloss: \", per_model_metrics['logloss']['train'])\n",
        "  print(\"Per fold val logloss: \", per_model_metrics['logloss']['val'])\n",
        "  \n",
        "  wandb.log({\n",
        "        \"Fold Avg. Train Logloss\": np.mean(per_model_metrics['logloss']['train']), \n",
        "        \"Fold Avg. Val Logloss\": np.mean(per_model_metrics['logloss']['val']),\n",
        "        }\n",
        "      )\n",
        "  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAhSGQuxzchu"
      },
      "outputs": [],
      "source": [
        "\n",
        "def create_paths(config):\n",
        "  config['local_model_dir'] = '/content/model_store'\n",
        "  config['drive_model_dir'] = os.path.join(config['drive_project_dir'], 'model_store')\n",
        "  \n",
        "  if not os.path.exists(config['local_model_dir']):\n",
        "    os.mkdir(config['local_model_dir'])\n",
        "  \n",
        "  if not os.path.exists(config['drive_model_dir']):\n",
        "    os.mkdir(config['drive_model_dir'])\n",
        "  \n",
        "  # -------------\n",
        "  \n",
        "  config['local_model_dir'] = os.path.join(config['local_model_dir'], config['model_name']) \n",
        "  config['drive_model_dir'] = os.path.join(config['drive_model_dir'], config['model_name']) \n",
        "\n",
        "  if not os.path.exists(config['local_model_dir']): \n",
        "    os.mkdir(config['local_model_dir'])\n",
        "  if not os.path.exists(config['drive_model_dir']): \n",
        "    os.mkdir(config['drive_model_dir'])\n",
        "  \n",
        "  # -------------\n",
        "\n",
        "  config['local_data_dir'] = '/content/data'\n",
        "  config['drive_data_dir'] = os.path.join(config['drive_project_dir'], 'data/')\n",
        "\n",
        "  config['local_feature_dir'] = '/content/feature_store'\n",
        "  config['drive_feature_dir'] = os.path.join(config['drive_project_dir'], 'feature_store')\n",
        "\n",
        "  if not os.path.exists(config['local_data_dir']):\n",
        "    os.mkdir(config['local_data_dir'])\n",
        "  \n",
        "  if not os.path.exists(config['local_feature_dir']):\n",
        "    os.mkdir(config['local_feature_dir'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p02CccbvRZPI"
      },
      "outputs": [],
      "source": [
        "\n",
        "def aggregate_preds(config, per_fold_test_preds, per_fold_test_preds_int, per_model_metrics=None): \n",
        "  if config['aggr_type'] == 'simple':\n",
        "    aggr_test_preds_cont = np.average(per_fold_test_preds, axis=0).flatten()\n",
        "    aggr_test_preds_int = np.argmax(aggr_test_preds_cont, axis=1).flatten()\n",
        "  elif config['aggr_type'] == 'auroc':\n",
        "    aggr_test_preds_cont = np.average(per_fold_test_preds, axis=0, weights=per_model_metrics['AUROC']['val'])\n",
        "    aggr_test_preds_int = np.argmax(aggr_test_preds_cont, axis=1).flatten()\n",
        "  elif config['aggr_type'] == 'logloss':\n",
        "    weights = 1/np.array(per_model_metrics['logloss']['val'])\n",
        "    # print('weights.shape: ', weights.shape)\n",
        "    # print('per_fold_test_preds.shape: ', per_fold_test_preds.shape)\n",
        "    \n",
        "    aggr_test_preds_cont = np.average(per_fold_test_preds, axis=0, weights=weights).flatten()\n",
        "    aggr_test_preds_int = convert_cont_preds_to_int(aggr_test_preds_cont)\n",
        "  elif config['aggr_type'] == 'mode':\n",
        "    aggr_test_preds_int = mode(per_fold_test_preds_int, axis=0)\n",
        "    aggr_test_preds_cont = aggr_test_preds_int\n",
        "  \n",
        "  return aggr_test_preds_cont, aggr_test_preds_int\n",
        "\n",
        "\n",
        "\n",
        "def test_model(config):\n",
        "  create_paths(config)\n",
        "\n",
        "  # ----------------------------------\n",
        "\n",
        "  model_training_config = get_model_config(config)\n",
        "  print(\"model_training_config: \", model_training_config)\n",
        "  for key in ['scale_data', 'scaler_type', 'handle_outliers', 'outlier_handling_method', \n",
        "              'feature_version', 'validate_only_comp_data', 'include_orig_train_data', 'include_orig_test_data', \n",
        "              'fold_split_type', 'num_folds', 'random_state', 'seed', \n",
        "              'dim_reduction', 'dim_red_method']:  \n",
        "    if key in model_training_config.keys():\n",
        "      print(f\"Overwriting value for {key} with: {model_training_config[key]}\")\n",
        "      config[key] = model_training_config[key]\n",
        "  \n",
        "  if config['dim_reduction'] and config['dim_red_method']=='PCA':\n",
        "    config['scale_data'] = True\n",
        "  \n",
        "  # ----------------------------------\n",
        "\n",
        "  train_df, test_df, sub_df, orig_data_df = get_data(config)\n",
        "  print(\"train_df.shape: \", train_df.shape)\n",
        "  print(\"test_df.shape: \", test_df.shape)\n",
        "  print(\"sub_df.shape: \", sub_df.shape)\n",
        "  print(\"orig_data_df.shape: \", orig_data_df.shape)\n",
        "  \n",
        "  # -------------------------------------------\n",
        "\n",
        "  if config['validate_only_comp_data']:\n",
        "    fold_idx_dict = generate_fold_idx(config, train_df)\n",
        "\n",
        "  if config['include_orig_data']: \n",
        "    train_df = pd.concat((train_df, orig_data_df), axis=0)\n",
        "    print(\"After appending orig data to train data: \")\n",
        "    print(\"train_df.shape: \", train_df.shape)\n",
        "  \n",
        "  if not config['validate_only_comp_data']:\n",
        "    fold_idx_dict = generate_fold_idx(config, train_df)\n",
        "  \n",
        "  for fold_num in fold_idx_dict.keys():\n",
        "    val_idx = fold_idx_dict[fold_num]['val_idx']\n",
        "    all_idx = np.arange(0, train_df.shape[0])\n",
        "    train_idx = np.setdiff1d(all_idx, val_idx)\n",
        "    fold_idx_dict[fold_num]['train_idx'] = train_idx\n",
        "  \n",
        "  print(\"Loading fold_idx_dict...\")\n",
        "  fold_idx_dict = load_fold_idx(config)\n",
        "  \n",
        "  # -------------------------------------------\n",
        "\n",
        "  test_ids = test_df.id.values\n",
        "  \n",
        "  # print(\"Before feature encoding: train_df.shape: \", train_df.shape)\n",
        "  # print(\"Before feature encoding: test_df.shape: \", test_df.shape)\n",
        "  # train_df, test_df, label_encoder = encode_data(config, train_df, test_df)\n",
        "  # print(\"After feature encoding: train_df.shape: \", train_df.shape)\n",
        "  # print(\"After feature encoding: test_df.shape: \", test_df.shape)\n",
        "  \n",
        "  # ---------------\n",
        "\n",
        "  print(\"Before feature extraction: train_df.shape: \", train_df.shape)\n",
        "  print(\"Before feature extraction: test_df.shape: \", test_df.shape)\n",
        "  train_df, test_df = extract_features(config, train_df, test_df)\n",
        "  print(\"After feature extraction: train_df.shape: \", train_df.shape)\n",
        "  print(\"After feature extraction: test_df.shape: \", test_df.shape)\n",
        "  \n",
        "  # ---------------\n",
        "\n",
        "  config = get_feature_cols(config, train_df)\n",
        "  print(\"# feature_cols: \", len(config['feature_cols']))\n",
        "  \n",
        "  # ------------------\n",
        "  \n",
        "  if config['handle_outliers']:\n",
        "    print(\"Before outlier handling: \")\n",
        "    print(f\"train_df.shape: {train_df.shape} \\t test_df.shape: {test_df.shape}\")\n",
        "    train_df, test_df = handle_outliers(config, train_df, test_df)\n",
        "    print(\"After outlier handling: \")\n",
        "    print(f\"train_df.shape: {train_df.shape} \\t test_df.shape: {test_df.shape}\")\n",
        "  \n",
        "  # ------------------\n",
        "\n",
        "  if config['dim_reduction'] and config['dim_red_method']=='PCA':\n",
        "    config['scale_data'] = True\n",
        "  \n",
        "  if config['scale_data']:\n",
        "    print(\"Scaling data...\")\n",
        "    train_df, test_df = scale_data_fn(config, train_df, test_df)\n",
        "    \n",
        "\n",
        "  # ------------------\n",
        "  if config['dim_reduction']:\n",
        "    if config['dim_red_method']=='PCA':\n",
        "      train_df, test_df = pca_dim_red(config, train_df, test_df)\n",
        "    elif config['dim_red_method']=='UMAP':\n",
        "      print(\"dim reduction method UMAP not yet supported...\")\n",
        "    else: \n",
        "      raise\n",
        "    \n",
        "  config = get_feature_cols(config, train_df)\n",
        "  print(\"config['feature_cols']): \", config['feature_cols'])\n",
        "  print(\"# feature_cols: \", len(config['feature_cols']))\n",
        "  \n",
        "\n",
        "  # ------------------------\n",
        "\n",
        "\n",
        "  # fold_idx_dict = generate_fold_idx(config, train_df)\n",
        "  \n",
        "  per_model_metrics = {\n",
        "                        'logloss': {'train': [], 'val': []},\n",
        "                        'AUROC': {'train': [], 'val': []},\n",
        "                        'f1_score': {'train': [], 'val': []},\n",
        "                      }\n",
        "\n",
        "  per_fold_test_preds = None\n",
        "  per_fold_test_preds_int = None\n",
        "  pred_cnt = 0\n",
        "\n",
        "  for fold_num in range(config['num_folds']):\n",
        "    if fold_num not in config['folds_to_train']:\n",
        "      continue\n",
        "    pred_cnt += 1\n",
        "    print(\"Training fold: \", fold_num)\n",
        "    config['curr_fold'] = fold_num\n",
        "\n",
        "    # -----------\n",
        "    fold_model_name = config['model_name'] + '_fold_' + str(config['curr_fold'])\n",
        "\n",
        "    train_idx = fold_idx_dict[fold_num]['train_idx']\n",
        "    val_idx = fold_idx_dict[fold_num]['val_idx']\n",
        "    print(\"len(train_idx): {} \\t len(val_idx): {}\".format(len(train_idx), len(val_idx)))\n",
        "    \n",
        "    train_data = train_df[config['feature_cols']].iloc[train_idx]\n",
        "    train_label = train_df[config['target_cols']].iloc[train_idx]\n",
        "\n",
        "    val_data = train_df[config['feature_cols']].iloc[val_idx]\n",
        "    val_label = train_df[config['target_cols']].iloc[val_idx]\n",
        "\n",
        "    test_data = test_df[config['feature_cols']]\n",
        "    \n",
        "    # --------\n",
        "\n",
        "    model = load_model(config)\n",
        "\n",
        "    train_pred_probs = model.predict_proba(train_data, ntree_limit=model.best_ntree_limit)\n",
        "    val_pred_probs = model.predict_proba(val_data, ntree_limit=model.best_ntree_limit)\n",
        "    test_pred_probs = model.predict_proba(test_data, ntree_limit=model.best_ntree_limit)\n",
        "    \n",
        "    train_preds = np.argmax(train_pred_probs, axis=1)\n",
        "    val_preds = np.argmax(val_pred_probs, axis=1)\n",
        "    test_preds = np.argmax(test_pred_probs, axis=1)\n",
        "\n",
        "    # ------------------\n",
        "\n",
        "    train_logloss = log_loss(train_label.values, train_pred_probs[:, 1])\n",
        "    val_logloss = log_loss(val_label.values, val_pred_probs[:, 1])\n",
        "    train_auroc = roc_auc_score(train_label.values, train_pred_probs[:, 1])\n",
        "    val_auroc = roc_auc_score(val_label.values, val_pred_probs[:, 1])\n",
        "    train_f1 = f1_score(train_label.values, train_preds, average='weighted')\n",
        "    val_f1 = f1_score(val_label.values, val_preds, average='weighted')\n",
        "    \n",
        "    \n",
        "    # ------------------\n",
        "    \n",
        "    per_model_metrics['logloss']['train'].append(train_logloss)\n",
        "    per_model_metrics['logloss']['val'].append(val_logloss)\n",
        "    per_model_metrics['AUROC']['train'].append(train_auroc)\n",
        "    per_model_metrics['AUROC']['val'].append(val_auroc)\n",
        "    per_model_metrics['f1_score']['train'].append(train_f1)\n",
        "    per_model_metrics['f1_score']['val'].append(val_f1)\n",
        "    \n",
        "    print(f\"Logloss: Train: {train_logloss} \\t Val: {val_logloss}\")\n",
        "    print(f\"AUROC: Train: {train_auroc} \\t Val: {val_auroc}\")\n",
        "    print(f\"F1 score: Train: {train_f1} \\t Val: {val_f1}\")\n",
        "    \n",
        "    test_pred_probs = np.reshape(test_pred_probs, newshape=(1, test_pred_probs.shape[0], test_pred_probs.shape[1]))\n",
        "    test_preds = np.reshape(test_preds, newshape=(1, test_preds.shape[0]))\n",
        "    \n",
        "    if per_fold_test_preds is None:\n",
        "      per_fold_test_pred_probs = test_pred_probs\n",
        "      per_fold_test_preds = test_preds\n",
        "    else:\n",
        "      per_fold_test_pred_probs = np.concatenate((per_fold_test_pred_probs, test_pred_probs), axis=0)\n",
        "      per_fold_test_preds = np.concatenate((per_fold_test_preds, test_preds), axis=0)\n",
        "     \n",
        "\n",
        "  print(\"Fold average stats.: \")\n",
        "  print(f\"Loss: Train: {np.mean(per_model_metrics['logloss']['train'])} \\t Val: {np.mean(per_model_metrics['logloss']['val'])}\")\n",
        "  print(f\"AUROC: Train: {np.mean(per_model_metrics['AUROC']['train'])} \\t Val: {np.mean(per_model_metrics['AUROC']['val'])}\")\n",
        "  print(f\"F1 score: Train: {np.mean(per_model_metrics['f1_score']['train'])} \\t Val: {np.mean(per_model_metrics['f1_score']['val'])}\")\n",
        "  \n",
        "  print(\"-\"*30)\n",
        "  # print(\"Per fold train wqkappa: \", per_model_metrics['wqkappa']['train'])\n",
        "  # print(\"Per fold val wqkappa: \", per_model_metrics['wqkappa']['val'])\n",
        "\n",
        "  print(\"Per fold train AUROC: \", per_model_metrics['AUROC']['train'])\n",
        "  print(\"Per fold val AUROC: \", per_model_metrics['AUROC']['val'])\n",
        "  \n",
        "  print(\"Per fold train logloss: \", per_model_metrics['logloss']['train'])\n",
        "  print(\"Per fold val logloss: \", per_model_metrics['logloss']['val'])\n",
        "\n",
        "  print(\"-\"*30)\n",
        "  \n",
        "  # ------------------\n",
        "\n",
        "  print(\"per_fold_test_pred_probs.shape: \", per_fold_test_pred_probs.shape)\n",
        "  print(\"per_fold_test_preds.shape: \", per_fold_test_preds.shape)\n",
        "  print(\"per_fold_test_pred_probs[:, :, 1].shape: \", per_fold_test_pred_probs[:, :, 1].shape)\n",
        "  \n",
        "  aggr_test_pred_probs, aggr_test_preds = \\\n",
        "                  aggregate_preds(config, per_fold_test_pred_probs[:, :, 1], per_fold_test_preds, per_model_metrics)\n",
        "  print(\"aggr_test_pred_probs[:3]: \", aggr_test_pred_probs[:3])\n",
        "  print(\"aggr_test_preds[:10]: \", aggr_test_preds[:10])\n",
        "\n",
        "  aggr_test_preds = np.reshape(aggr_test_preds, newshape=(aggr_test_preds.shape[0], 1))\n",
        "  # aggr_test_preds = label_encoder.inverse_transform(aggr_test_preds)\n",
        "  print(\"2. aggr_test_preds[:10]: \", aggr_test_preds[:10])\n",
        "  print(\"2. aggr_test_preds.shape: \", aggr_test_preds.shape)\n",
        "\n",
        "  sub_df = pd.DataFrame([])\n",
        "  sub_df['id'] = test_ids \n",
        "  sub_df['Class'] = aggr_test_pred_probs\n",
        "  sub_df.to_csv(os.path.join(config['local_model_dir'], 'sample_submission.csv'), index=False)\n",
        "  shutil.copy(os.path.join(config['local_model_dir'], 'sample_submission.csv'), \n",
        "              os.path.join(config['drive_model_dir'], 'sample_submission.csv'))\n",
        "\n",
        "\n",
        "# submission_{notebook_name}_{date}_{time}.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8W7JhZgr88if"
      },
      "outputs": [],
      "source": [
        "\n",
        "def model_analysis():\n",
        "  config = get_config()\n",
        "  create_paths(config)\n",
        "  \n",
        "  train_df, test_df, sub_df = get_data(config)\n",
        "  print(\"train_df.shape: \", train_df.shape)\n",
        "  test_ids = test_df.Id.values\n",
        "\n",
        "  train_df, test_df, label_encoder = encode_data(config, train_df, test_df)\n",
        "\n",
        "  config = get_feature_cols(config, train_df)\n",
        "\n",
        "  fold_idx_dict = generate_fold_idx(config, train_df)\n",
        "  \n",
        "  for fold_num in range(config['num_folds']):\n",
        "    if fold_num not in config['folds_to_train']:\n",
        "      continue\n",
        "    config['curr_fold'] = fold_num\n",
        "\n",
        "    # -----------\n",
        "    # fold_model_name = config['model_name'] + '_fold_' + str(config['curr_fold'])\n",
        "\n",
        "    # train_idx = fold_idx_dict[fold_num]['train_idx']\n",
        "    # val_idx = fold_idx_dict[fold_num]['val_idx']\n",
        "    # print(\"len(train_idx): {} \\t len(val_idx): {}\".format(len(train_idx), len(val_idx)))\n",
        "    \n",
        "    # train_data = train_df[config['feature_cols']].iloc[train_idx]\n",
        "    # train_label = train_df[config['target_cols']].iloc[train_idx]\n",
        "\n",
        "    # val_data = train_df[config['feature_cols']].iloc[val_idx]\n",
        "    # val_label = train_df[config['target_cols']].iloc[val_idx]\n",
        "\n",
        "    # test_data = test_df[config['feature_cols']]\n",
        "    \n",
        "    # --------\n",
        "\n",
        "    model = load_model(config)\n",
        "    plt.figure(figsuze=(12, 10))\n",
        "    xgb.plot_importance(model)\n",
        "    plt.title(f\"Fold: {fold_num}\")\n",
        "    plt.show()\n",
        "    plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MoQ2_0Dbzccr",
        "outputId": "22524e5e-8c79-42ba-bc64-79565a424e9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOT USING GPU!!!!!! Parameter 'use_gpu_if_available' is set to TRUE; But NO GPU IS VISIBLE!!!!!\n",
            "Read shape: train_df.shape:  (117564, 10)\n",
            "Read shape: test_df.shape:  (78377, 9)\n",
            "Read shape: sub_df.shape:  (78377, 2)\n",
            "train_df.shape:  (117564, 11)\n",
            "test_df.shape:  (78377, 9)\n",
            "sub_df.shape:  (78377, 2)\n",
            "orig_data_df.shape:  (17898, 11)\n",
            "After appending orig data to train data: \n",
            "train_df.shape:  (135462, 11)\n",
            "Saving fold_idx_dict...\n",
            "Before feature extraction: train_df.shape:  (135462, 11)\n",
            "Before feature extraction: test_df.shape:  (78377, 9)\n",
            "After feature extraction: train_df.shape:  (135462, 11)\n",
            "After feature extraction: test_df.shape:  (78377, 9)\n",
            "config['feature_cols']):  ['Mean_Integrated', 'SD', 'EK', 'Skewness', 'Mean_DMSNR_Curve', 'SD_DMSNR_Curve', 'EK_DMSNR_Curve', 'Skewness_DMSNR_Curve']\n",
            "# feature_cols:  8\n",
            "config['feature_cols']):  ['Mean_Integrated', 'SD', 'EK', 'Skewness', 'Mean_DMSNR_Curve', 'SD_DMSNR_Curve', 'EK_DMSNR_Curve', 'Skewness_DMSNR_Curve']\n",
            "# feature_cols:  8"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:413: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:413: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:7l2cuxc8) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Fold Avg. Train Logloss</td><td>▁</td></tr><tr><td>Fold Avg. Val Logloss</td><td>▁</td></tr><tr><td>Per Epoch Train logloss</td><td>█▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Per Epoch Val logloss</td><td>█▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Fold Avg. Train Logloss</td><td>0.02794</td></tr><tr><td>Fold Avg. Val Logloss</td><td>0.03344</td></tr><tr><td>Per Epoch Train logloss</td><td>0.02211</td></tr><tr><td>Per Epoch Val logloss</td><td>0.03376</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">xgb_model_3</strong> at: <a href='https://wandb.ai/jaideepmurkute/playground_s03_e10/runs/7l2cuxc8' target=\"_blank\">https://wandb.ai/jaideepmurkute/playground_s03_e10/runs/7l2cuxc8</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230309_050023-7l2cuxc8/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:7l2cuxc8). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230309_053646-k9j50lvx</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jaideepmurkute/playground_s03_e10/runs/k9j50lvx' target=\"_blank\">xgb_model_3</a></strong> to <a href='https://wandb.ai/jaideepmurkute/playground_s03_e10' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/jaideepmurkute/playground_s03_e10' target=\"_blank\">https://wandb.ai/jaideepmurkute/playground_s03_e10</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/jaideepmurkute/playground_s03_e10/runs/k9j50lvx' target=\"_blank\">https://wandb.ai/jaideepmurkute/playground_s03_e10/runs/k9j50lvx</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training fold:  0\n",
            "len(train_idx): 111949 \t len(val_idx): 23513\n",
            "Setting scale_pos_weight to:  9.750888312686065\n",
            "Training model ...\n",
            "[0]\tvalidation_0-logloss:0.60647\tvalidation_1-logloss:0.60572\n",
            "[50]\tvalidation_0-logloss:0.07164\tvalidation_1-logloss:0.06886\n",
            "[100]\tvalidation_0-logloss:0.05654\tvalidation_1-logloss:0.05697\n",
            "[150]\tvalidation_0-logloss:0.05156\tvalidation_1-logloss:0.05408\n",
            "[200]\tvalidation_0-logloss:0.04723\tvalidation_1-logloss:0.05181\n",
            "[250]\tvalidation_0-logloss:0.04393\tvalidation_1-logloss:0.05011\n",
            "[300]\tvalidation_0-logloss:0.04080\tvalidation_1-logloss:0.04836\n",
            "[350]\tvalidation_0-logloss:0.03764\tvalidation_1-logloss:0.04663\n",
            "[400]\tvalidation_0-logloss:0.03523\tvalidation_1-logloss:0.04552\n",
            "[450]\tvalidation_0-logloss:0.03246\tvalidation_1-logloss:0.04420\n",
            "[500]\tvalidation_0-logloss:0.03036\tvalidation_1-logloss:0.04344\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-335be3fd13f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'choice'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m   \u001b[0mtrain_k_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'choice'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-63a2d1bfed41>\u001b[0m in \u001b[0;36mtrain_k_folds\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training model ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     model.fit(train_data, train_label, \n\u001b[0m\u001b[1;32m    165\u001b[0m               eval_set=[(train_data, train_label), \n\u001b[1;32m    166\u001b[0m                         (val_data, val_label)], \n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1488\u001b[0m             )\n\u001b[1;32m   1489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1490\u001b[0;31m             self._Booster = train(\n\u001b[0m\u001b[1;32m   1491\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/xgboost/callback.py\u001b[0m in \u001b[0;36mafter_iteration\u001b[0;34m(self, model, epoch, dtrain, evals)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Dataset name should not contain `-`'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0mscore\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_margin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m             \u001b[0msplited\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# into datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;31m# split up `test-error:0.1234`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36meval_set\u001b[0;34m(self, evals, iteration, feval, output_margin)\u001b[0m\n\u001b[1;32m   1987\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1988\u001b[0m         _check_call(\n\u001b[0;32m-> 1989\u001b[0;31m             _LIB.XGBoosterEvalOneIter(\n\u001b[0m\u001b[1;32m   1990\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1991\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "config = {\n",
        "    'choice': 1, \n",
        "    'random_state': 21, # 2640\n",
        "    'aggr_type': 'logloss',  # simple / logloss\n",
        "    \n",
        "    'model_name': 'xgb_model_1', \n",
        "    \n",
        "    'feature_version': None,  # None, v1, v2, v3\n",
        "    'include_orig_data': True,\n",
        "    'validate_only_comp_data': True, \n",
        "    \n",
        "    'handle_outliers': False, \n",
        "    'outlier_handling_method': 'iqr', \n",
        "    \n",
        "    'scale_data': True, \n",
        "    'scaler_type': 'standard',  # standard / robust / minmax\n",
        "\n",
        "    #### OrdinalEncoder ??????????????? <<<<<<<<<<<<<<<<  <<<<<<<<<<<\n",
        "    \n",
        "    'dim_reduction': False, \n",
        "    'dim_red_method': 'PCA',   # PCA / UMAP (UMAP not impl yet)\n",
        "    \n",
        "    'enable_categorical': False, \n",
        "    'fold_split_type': 'strat_kfold',  # kfold, strat_kfold\n",
        "    'num_folds': 5, \n",
        "    'folds_to_train': [0], #  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "    \n",
        "    'booster': 'gbtree', # 'gbtree', #'gbtree', # gbtree, gblinear, dart;   defalt: gbtree\n",
        "    'tree_method': 'hist', # auto, exact, approx, hist, gpu_hist,   auto: Use heuristic to choose the fastest method.\n",
        "    'n_estimators': 100, # 9999, \n",
        "    'early_stopping_rounds': 30, #200, \n",
        "\n",
        "    'colsample_bytree': 1.0, \n",
        "    'subsample': 1.0, \n",
        "    \n",
        "    'max_depth': 5, # 6, \n",
        "    'max_leaves': 32, # 48,  \n",
        "    'learning_rate': 0.1,  \n",
        "\n",
        "    'reg_alpha': 0.0,  # Default: 0\n",
        "    'reg_lambda': 0.0,  # Default: 0\n",
        "    \n",
        "    # for the dart booster\n",
        "    'sample_type': 'uniform',  # 'uniform'/ 'weighted'; Default: uniform\n",
        "    'normalize_type': 'tree',  # 'tree' / 'forest'; Default: tree\n",
        "    'rate_drop': 0.3,  # Default: 0.0\n",
        "    'skip_drop': 0.6,  # Default: 0.0 \n",
        "\n",
        "    'max_bin': 512,  # Default: 256\n",
        "    'min_child_weight': 1, # Default: 1\n",
        "    'gamma': 0,   # default: 0\n",
        "\n",
        "    # if 'auto'; will be overridden as sum(negative instances) / sum(positive instances). \n",
        "    # Else; provided value will be used.\n",
        "    # Defaut: 1\n",
        "    'scale_pos_weight': 'auto',  # 'auto' / 10 / 25 etc.\n",
        "\n",
        "    'verbosity': 1,\n",
        "\n",
        "    'objective': 'reg:logistic', \n",
        "    'eval_metric': 'logloss',  \n",
        "\n",
        "    'use_gpu_if_available': True, \n",
        "    'predictor': 'gpu_predictor',\n",
        "    'use_wandb': True, # Defaults to true if choice==3.\n",
        "    'n_jobs': -1, \n",
        "    'data_dir': '/content/data/', \n",
        "    'drive_project_dir': '/content/drive/MyDrive/Playground Series/S03_E12', \n",
        "    'project_name': 'playground_s03_e12', \n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "if config['use_gpu_if_available']:\n",
        "  if torch.cuda.is_available():\n",
        "    config['gpu_id'] = 0\n",
        "    config['tree_method'] = 'gpu_hist'\n",
        "    config['predictor'] = 'gpu_predictor'\n",
        "    print(\"GPU available... XGBoost will use GPU...\")\n",
        "  else:\n",
        "    print(\"NOT USING GPU!!!!!! Parameter 'use_gpu_if_available' is set to TRUE; But NO GPU IS VISIBLE!!!!!\")\n",
        "    if config['tree_method'] == 'gpu_hist': config['tree_method'] = 'hist'\n",
        "    if config['predictor'] == 'gpu_predictor': config['predictor'] = 'cpu_predictor'\n",
        "else:\n",
        "  if config['tree_method'] == 'gpu_hist': config['tree_method'] = 'hist'\n",
        "  if config['predictor'] == 'gpu_predictor': config['predictor'] = 'cpu_predictor' \n",
        "  print(\"NOT USING GPU!!!!!! Parameter 'use_gpu_if_available' is set to False!!!!!!!\")    \n",
        "\n",
        "\n",
        "if config['dim_reduction'] and config['dim_red_method']=='PCA':\n",
        "  config['scale_data'] = True\n",
        "\n",
        "\n",
        "if config['choice'] == 3: config['use_wandb'] = True\n",
        "\n",
        "if config['use_wandb']:\n",
        "  os.environ['WANDB_MODE'] = 'online'\n",
        "  try: \n",
        "    wandb.login(key='d60ad29783a045de090c17001912975dc8f9f2e2') \n",
        "  except:\n",
        "    wandb.login()\n",
        "# else:\n",
        "# os.environ['WANDB_MODE'] = 'offline'\n",
        "\n",
        "set_seeds(config)\n",
        "\n",
        "if config['choice'] == 1:\n",
        "  train_k_folds()\n",
        "elif config['choice'] == 2:\n",
        "  test_model(config)\n",
        "elif config['choice'] == 3:\n",
        "  sweep_configs = {\n",
        "      \"method\": \"grid\",\n",
        "      \"metric\": {\n",
        "          \"name\": \"Fold Avg. Val Logloss\",\n",
        "          \"goal\": \"minimize\",  # this wqkappa is output of sklearn function after predictions. SO can maximize.\n",
        "      },\n",
        "      \"parameters\": { \n",
        "          # \"colsample_bytree\": {\n",
        "          #     \"values\": [0.6, 0.8, 1.0], \n",
        "          # },\n",
        "          # \"subsample\": {\n",
        "          #     \"values\": [0.6, 0.8, 1.0], \n",
        "          # },\n",
        "          # \"max_depth\": {\n",
        "          #     \"values\": [5, 8, 12, 24]\n",
        "          # },\n",
        "          # 'max_leaves': {\n",
        "          #     'values': [8, 16, 32, 64],\n",
        "          # },\n",
        "          # \"reg_alpha\": {\n",
        "          #     \"values\": [0, 1.0, 2.0, 5.0]\n",
        "          # },\n",
        "          # \"reg_lambda\": {\n",
        "          #     \"values\": [0, 1.0, 2.0, 5.0]\n",
        "          # },\n",
        "          # \"learning_rate\": {\n",
        "          #     \"values\": [0.01, 0.05, 0.1, 0.3, 0.5]\n",
        "          # }\n",
        "          \"random_state\": {\n",
        "              \"values\": random.sample(range(1, 9999), 50), # [0.01, 0.05, 0.1, 0.3, 0.5]\n",
        "          },\n",
        "          # \"max_bin\": {\n",
        "          #     \"values\": [64, 128, 256],\n",
        "          # },\n",
        "          # \"min_child_weight\": {\n",
        "          #     \"values\": [1, 16, 32],\n",
        "          # },\n",
        "          # \"gamma\": {\n",
        "          #     \"values\": [0, 2, 5, 10],\n",
        "          # },\n",
        "        }\n",
        "  }\n",
        "  print(\"Running sweep>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
        "  sweep_id = wandb.sweep(sweep=sweep_configs, project=config['project_name']+'_sweep')\n",
        "  wandb.agent(sweep_id=sweep_id, function=train_k_folds, count=50)\n",
        "elif config['choice'] == 4:\n",
        "  model_analysis()\n",
        "else:\n",
        "  raise ValueError(f\"Incorrect value for 'choice'={config['choice']} in config\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAk-r7kTKG-o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "7b7ca9c2-1031-404f-8633-929a96e862ec"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-9c9a2cba73bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
          ]
        }
      ],
      "source": [
        "raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Azej78AE3LJ5"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# base_path = '/content/data'\n",
        "# train_df = pd.read_csv(os.path.join(base_path, 'train.csv'))\n",
        "# test_df = pd.read_csv(os.path.join(base_path, 'test.csv'))\n",
        "# orig_data_df = pd.read_csv(os.path.join(base_path, 'orig_data.csv'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sqjh21yBKXPM"
      },
      "outputs": [],
      "source": [
        "# train_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UTpdA_wKXLg"
      },
      "outputs": [],
      "source": [
        "\n",
        "# sub_df = pd.read_csv('/content/model_store/xgb_model_1/sample_submission.csv')\n",
        "# sub_df\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TGlWc-H5E416"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}